{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"IR_CSV.csv\")\n",
    "stop_words=pd.read_csv(\"stop_words.csv\")\n",
    "punctuations=pd.read_csv(\"punctuations.csv\")\n",
    "mokasar=pd.read_csv(\"mokasar.csv\")\n",
    "harekat=pd.read_csv(\"harekat.csv\")\n",
    "verbs=pd.read_csv(\"verbs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['content'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def tokenize(x):\n",
    "    return x.split()\n",
    "tokens=[]\n",
    "for doc in data[\"content\"]:\n",
    "    doc=re.sub('http://\\S+|https://\\S+',\"\",doc)\n",
    "    doc=doc.replace(\"انتهای پیام\",\"\")\n",
    "    tokens.append(set(doc.split()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(list1,list2):\n",
    "    i=j=0\n",
    "    m=[]\n",
    "    while(i<len(list1) and j<len(list2)):\n",
    "        \n",
    "        if list1[i]<list2[j]:\n",
    "            m.append(list1[i])\n",
    "            i+=1\n",
    "        elif list1[i]==list2[j]:\n",
    "            m.append(list1[i])\n",
    "            i+=1\n",
    "            j+=1\n",
    "        else:\n",
    "            m.append(list2[j])\n",
    "            j+=1\n",
    "    while(i<len(list1)):\n",
    "        m.append(list1[i])\n",
    "        i+=1\n",
    "    while(j<len(list2)):\n",
    "        m.append(list2[j])\n",
    "        j+=1\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# یکسان سازی"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# اعداد و علائم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_to_remove=''.join(punctuations[\"punctuations\"].values.tolist()).replace(\" \",\"\")\n",
    "chars_to_remove+=\"٠١٢٣٤٥٦٧٨٩\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# حرکت ها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "harekats=\"\".join(harekat[\"sign\"].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# یکسان سازی حروف"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chardict={'ؤ':'و',\n",
    "         'ي':'ی',\n",
    "         'أ':'ا',\n",
    "         'إ':'ا',\n",
    "         'آ':'ا',\n",
    "         'ك':'ک',\n",
    "         'ة':'ه'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# جمع مکسر"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mokasar_dict=mokasar.set_index('jam').T.to_dict(\"list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# حذف پسوند"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns = [\n",
    "    \"ام\",\n",
    "    \"ات\",\n",
    "    \"اش\",\n",
    "    \"مان\",\n",
    "    \"تان\",\n",
    "    \"شان\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " سرزمینهایمان:\n",
    " سرزمین + های + مان"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ضمیر‌های متصل آخر را حذف می‌کنیم"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تر* و ها* را حذف می‌کنیم"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ی هکسره را حذف می کنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_suffix(t):\n",
    "    for pr in pronouns:\n",
    "        if t.endswith(\"\\u200c\"+pr):\n",
    "            t = t.replace(\"\\u200c\"+pr, \"\")\n",
    "            break\n",
    "    if \"\\u200c\"+\"ها\" in t:\n",
    "            t = t.replace(t[t.rfind(\"\\u200c\"):], \"\")\n",
    "    if \"\\u200c\"+\"تر\" in t:\n",
    "        t = t.replace(t[t.rfind(\"\\u200c\"):], \"\")\n",
    "    if t.endswith(\"\\u200c\"+\"ی\"):\n",
    "        t = t.replace(\"\\u200c\"+\"ی\", \"\")\n",
    "    if t.endswith(\"\\u200c\"+\"ای\"):\n",
    "        t = t.replace(\"\\u200c\"+\"ای\", \"\")\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# حذف پیشوند"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = [\"بیش\", \"پس\", \"پی\", \"بی\",\"به\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_prefix(t):\n",
    "    for pr in prefix:\n",
    "        if t.startswith(pr+\"\\u200c\"):\n",
    "            t = t.replace(pr+\"\\u200c\", \"\")\n",
    "            break\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ریشه یابی افعال"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prons=[\n",
    "    \"م\",\n",
    "    \"ی\",\n",
    "    \"یم\",\n",
    "    \"ید\",\n",
    "    \"ند\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_past(verb):\n",
    "    verbs={}\n",
    "    all_verbs=[verb]\n",
    "    for pr in prons:\n",
    "        verbs[verb+pr]=verb\n",
    "        all_verbs.append(verb+pr)\n",
    "    for v in all_verbs:\n",
    "        verbs[\"می\"+v]=verb\n",
    "        verbs[\"می\\u200c\"+v]=verb\n",
    "    return verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_present(verb):\n",
    "    verbs={}\n",
    "    all_verbs=[verb]\n",
    "    for pr in prons:\n",
    "        verbs[verb+pr]=verb\n",
    "        all_verbs.append(verb+pr)\n",
    "    verbs[verb+\"د\"]=verb\n",
    "    all_verbs.append(verb+\"د\")\n",
    "    for v in all_verbs:\n",
    "        verbs[\"می\"+v]=verb\n",
    "        verbs[\"می\\u200c\"+v]=verb\n",
    "        verbs[\"ب\"+v]=verb\n",
    "    return verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_dict={}\n",
    "for past in verbs[\"past\"]:\n",
    "    d=get_all_past(past)\n",
    "    verbs_dict.update(d)\n",
    "for present in verbs[\"present\"]:\n",
    "    d=get_all_present(present)\n",
    "    verbs_dict.update(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# کلمات چند جزیی"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "بعد از اینکه از نیم‌فاصله استفاده کردیم و کلمات را جدا کردیم حال می‌توانیم نیم فاصله را حذف کنیم تا کلمات چند جزیی یکسان شوند"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hspace(t):\n",
    "    t2=t\n",
    "    if \"\\u200c\" in t:\n",
    "        t2=t.replace(\"\\u200c\", \"\")\n",
    "    return t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_doc(doc):\n",
    "    normed=[]\n",
    "    doc=set(doc)\n",
    "    for t in doc:\n",
    "        if t in stop_words:\n",
    "            t=\"\"\n",
    "            continue\n",
    "        t=t.translate(str.maketrans('','',chars_to_remove)) #علائم نگارشی اعداد فارسی انگلیسی عربی و...\n",
    "        t=t.translate(str.maketrans('','',harekats)) #حرکت های زبان فارسی\n",
    "        t=t.translate(str.maketrans(chardict)) # یکسان سازی حروف\n",
    "        if t in mokasar_dict.keys(): # جمع مکسر\n",
    "            t=mokasar_dict[t][0]\n",
    "        t=norm_suffix(t) # حذف پسوند\n",
    "        t=norm_prefix(t)\n",
    "        if t in verbs_dict.keys(): # ریشه یابی فعل\n",
    "            t=verbs_dict[t]\n",
    "        t=hspace(t)\n",
    "        normed.append(t)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "normalized_tokens=[]\n",
    "for i in tokens:\n",
    "    normalized_tokens.append(normalize_doc(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inverted_index(tokens):\n",
    "    inv_idx=OrderedDict()\n",
    "    for docid in range(len(tokens)):\n",
    "        for token in tokens[docid]:\n",
    "            if token in inv_idx.keys():\n",
    "                inv_idx[token].append(docid)\n",
    "            else:\n",
    "                inv_idx[token]=[docid]\n",
    "    return inv_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 808 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inv_idx=build_inverted_index(normalized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_query(q):\n",
    "    if q[0] not in inv_idx.keys():\n",
    "        return \"no occurrences found\"\n",
    "    postings = inv_idx[q[0]]\n",
    "    return data.loc[data.index[postings]][\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_query(q):\n",
    "    postings=[]\n",
    "    ranks={}\n",
    "    for w in q:\n",
    "        if w in inv_idx.keys():\n",
    "            for doc_id in inv_idx[w]:\n",
    "                if doc_id in ranks.keys():\n",
    "                    ranks[doc_id]+=1\n",
    "                else:\n",
    "                    ranks[doc_id]=1\n",
    "                    \n",
    "    ranks = sorted(ranks.items(), key=lambda x: x[1], reverse=True)\n",
    "    postings=[idx for idx,rank in ranks]\n",
    "    return data.loc[data.index[postings]][\"url\"],ranks[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4667    https://www.isna.ir/news/98041507605/مبالغ-اضا...\n",
       "5148    https://www.isna.ir/news/98091712625/برداشت-۱۰...\n",
       "6990    https://www.isna.ir/news/98091712625/برداشت-۱۰...\n",
       "6993    https://www.isna.ir/news/98091712625/برداشت-۱۰...\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quer=\"علی‌الحساب\"\n",
    "q=normalize_doc(quer.split())\n",
    "single_query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['یزدیزاده']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "930    https://www.isna.ir/news/99111914509/رحمان-رضا...\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quer=\"یزدی‌زاده\"\n",
    "q=normalize_doc(quer.split())\n",
    "print(q)\n",
    "single_query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['علیالحساب']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4667    https://www.isna.ir/news/98041507605/مبالغ-اضا...\n",
       "5148    https://www.isna.ir/news/98091712625/برداشت-۱۰...\n",
       "6990    https://www.isna.ir/news/98091712625/برداشت-۱۰...\n",
       "6993    https://www.isna.ir/news/98091712625/برداشت-۱۰...\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quer=\"علی‌الحساب\"\n",
    "q=normalize_doc(quer.split())\n",
    "print(q)\n",
    "single_query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['عصاره', 'ملت', 'فضائل']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3155    https://www.isna.ir/news/98112216539/فروزنده-ا...\n",
       " 6726    https://www.isna.ir/news/98050200866/واکنش-این...\n",
       " 6729    https://www.isna.ir/news/98050200866/واکنش-این...\n",
       " 1133    https://www.isna.ir/news/98030401704/کولاکوویچ...\n",
       " 1737    https://www.isna.ir/news/99011105670/بیانیه-جه...\n",
       "                               ...                        \n",
       " 6477    https://www.isna.ir/news/99121309975/اقدامات-ف...\n",
       " 6515    https://www.isna.ir/news/99122619749/بهره-بردا...\n",
       " 6516    https://www.isna.ir/news/99122721186/پیام-روسا...\n",
       " 6523    https://www.isna.ir/news/99122721186/پیام-روسا...\n",
       " 6989    https://www.isna.ir/news/98091611102/هرخانه-یک...\n",
       " Name: url, Length: 222, dtype: object,\n",
       " 2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quer=\"عصاره فضائل ملت\"\n",
    "q=normalize_doc(quer.split())\n",
    "print(q)\n",
    "multi_query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['میکروب', 'پریدنتال', 'پاکت']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6995    https://www.isna.ir/news/98092015395/اصلی-ترین...\n",
       " 6998    https://www.isna.ir/news/98092015395/اصلی-ترین...\n",
       " 5929    https://www.isna.ir/news/99060504370/هشدارهایی...\n",
       " 4040    https://www.isna.ir/news/99092821555/عرضه-شوین...\n",
       " 4570    https://www.isna.ir/news/98031305827/خیز-منسوج...\n",
       " 4648    https://www.isna.ir/news/98040904454/عرضه-نانو...\n",
       " 5257    https://www.isna.ir/news/98102720683/معرفی-میک...\n",
       " 5504    https://www.isna.ir/news/99012715875/بهترین-رف...\n",
       " 5784    https://www.isna.ir/news/99042518891/حفظ-بهداش...\n",
       " 6097    https://www.isna.ir/news/99072317682/علائم-تنف...\n",
       " 6284    https://www.isna.ir/news/99092821555/عرضه-شوین...\n",
       " 6386    https://www.isna.ir/news/99111309406/واکسن-روس...\n",
       " 6489    https://www.isna.ir/news/99121712749/اختراع-نس...\n",
       " 6491    https://www.isna.ir/news/99121712854/توصیه-وزا...\n",
       " 6702    https://www.isna.ir/news/98041708893/شناسایی-ب...\n",
       " 6708    https://www.isna.ir/news/98041708893/شناسایی-ب...\n",
       " 6942    https://www.isna.ir/news/98082012554/آیا-کاپیت...\n",
       " 6945    https://www.isna.ir/news/98082012554/آیا-کاپیت...\n",
       " 1503    https://www.isna.ir/news/98092115743/قضاوت-۲-د...\n",
       " 4830    https://www.isna.ir/news/98052813869/فردا-هم-م...\n",
       " 6654    https://www.isna.ir/news/98031205462/همه-چیز-د...\n",
       " 6656    https://www.isna.ir/news/98031205462/همه-چیز-د...\n",
       " 6659    https://www.isna.ir/news/98031205462/همه-چیز-د...\n",
       " 6662    https://www.isna.ir/news/98031205462/همه-چیز-د...\n",
       " Name: url, dtype: object,\n",
       " 5)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quer=\"پاکت پریدنتال میکروب\"\n",
    "q=normalize_doc(quer.split())\n",
    "print(q)\n",
    "multi_query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['دانشگاهی', 'و', 'نخبگان', 'بنیاد', 'جهاد']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4228    https://www.isna.ir/news/99120100312/رویداد-خا...\n",
       " 4424    https://www.isna.ir/news/98021407530/تشریح-پیا...\n",
       " 5135    https://www.isna.ir/news/98091208462/با-سیاسی-...\n",
       " 1251    https://www.isna.ir/news/98050904866/تعهدات-جد...\n",
       " 2756    https://www.isna.ir/news/98050301495/از-بررسی-...\n",
       "                               ...                        \n",
       " 6992    https://www.isna.ir/news/98091813677/تاکید-مسئ...\n",
       " 6993    https://www.isna.ir/news/98091712625/برداشت-۱۰...\n",
       " 6994    https://www.isna.ir/news/98091813677/تاکید-مسئ...\n",
       " 6996    https://www.isna.ir/news/98092015327/انواع-دیا...\n",
       " 6999    https://www.isna.ir/news/98092015327/انواع-دیا...\n",
       " Name: url, Length: 6889, dtype: object,\n",
       " 6)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quer=\"بنیاد نخبگان و جهاد دانشگاهی\"\n",
    "q=normalize_doc(quer.split())\n",
    "print(q)\n",
    "multi_query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['حمایت', 'سازمان', 'مصرف', 'کننده', 'از']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5312    https://www.isna.ir/news/98111812880/باید-با-س...\n",
       " 1808    https://www.isna.ir/news/99022316996/متن-کامل-...\n",
       " 6665    https://www.isna.ir/news/98032008951/از-تیراند...\n",
       " 6667    https://www.isna.ir/news/98032008951/از-تیراند...\n",
       " 6669    https://www.isna.ir/news/98032008951/از-تیراند...\n",
       "                               ...                        \n",
       " 6992    https://www.isna.ir/news/98091813677/تاکید-مسئ...\n",
       " 6994    https://www.isna.ir/news/98091813677/تاکید-مسئ...\n",
       " 6996    https://www.isna.ir/news/98092015327/انواع-دیا...\n",
       " 6997    https://www.isna.ir/news/98092216157/پنجمین-مو...\n",
       " 6999    https://www.isna.ir/news/98092015327/انواع-دیا...\n",
       " Name: url, Length: 6566, dtype: object,\n",
       " 8)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quer=\"سازمان حمایت از مصرف کننده\"\n",
    "q=normalize_doc(quer.split())\n",
    "print(q)\n",
    "multi_query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34617"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inv_idx.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# یک ایده برای انکه میدان تبدیل به دان نشود"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "از آنجا که برای ریشه یابی افعال یک مپ درست کردیم دیگر پیشوند می را حذف نمیکنیم بلکه تمام شکل‌های فعل که می‌توان از بن ماضی و مضارع تولید کرد را می‌سازیم و سپس بررسی می‌کنیم که کل کلمه با افعال ما برابر است یا نه"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "درمورد بقیه‌ی پسوندها و پیشوندها نیز از طریق وجود نیم فاصله می‌توان فهمید که واقعا کلمه پسوند دارد یا نه"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ایده‌ی دیگر در مورد پسوندهایی که با نیم‌فاصله وارد نمی‌شوند آن است که بعد از حذف پسوند بررسی کنیم طول کلمه بیشتر از ۳ باشد( برای کلماتی مثل طاها)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "و ایده‌ی آخر آن است که بعد از تشکیل ایندکس پسوندها را جدا کنیم و بررسی کنیم با حذف پسوند کلمه‌ی به وجود آمده در دیکشنری وجود دارد یا خیر\n",
    "البته می‌توانیم از یک دیکشنری کامل هم کمک بگیریم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
